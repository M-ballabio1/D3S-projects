{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-12T10:19:29.898313Z","iopub.execute_input":"2022-02-12T10:19:29.898598Z","iopub.status.idle":"2022-02-12T10:19:49.082931Z","shell.execute_reply.started":"2022-02-12T10:19:29.898569Z","shell.execute_reply":"2022-02-12T10:19:49.080513Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nimport os\n!ls ../input/","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:56:43.243056Z","iopub.execute_input":"2022-02-12T16:56:43.243320Z","iopub.status.idle":"2022-02-12T16:56:43.961579Z","shell.execute_reply.started":"2022-02-12T16:56:43.243291Z","shell.execute_reply":"2022-02-12T16:56:43.960768Z"},"_kg_hide-input":true,"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"markdown","source":"# **CNN X-Ray images classification**","metadata":{}},{"cell_type":"markdown","source":"Il dataset è organizzato in 3 cartelle (train, test, val) e contiene sottocartelle per ciascuna categoria di immagini (polmonite/normale). Sono disponibili 5.863 immagini a raggi X (JPEG) e 2 categorie (polmonite/normale).\n\nLe immagini radiografiche del torace (anteriore-posteriore) sono state selezionate da studi di coorti retrospettive di pazienti pediatrici di età compresa tra 1 e 5 anni del Guangzhou Women and Children's Medical Center, Guangzhou.","metadata":{}},{"cell_type":"code","source":"Image(\"../input/immagini/confronto (1).png\")","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:56:47.157149Z","iopub.execute_input":"2022-02-12T16:56:47.157951Z","iopub.status.idle":"2022-02-12T16:56:47.185131Z","shell.execute_reply.started":"2022-02-12T16:56:47.157902Z","shell.execute_reply":"2022-02-12T16:56:47.184474Z"},"_kg_hide-input":true,"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport h5py\nimport shutil\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:37:26.887508Z","iopub.execute_input":"2022-02-12T16:37:26.887761Z","iopub.status.idle":"2022-02-12T16:37:26.898503Z","shell.execute_reply.started":"2022-02-12T16:37:26.887732Z","shell.execute_reply":"2022-02-12T16:37:26.897785Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"train_folder= '/kaggle/input/chest-xray-pneumonia/chest_xray/train/'\nval_folder = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/'\ntest_folder = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/'","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:37:12.749308Z","iopub.execute_input":"2022-02-12T14:37:12.749580Z","iopub.status.idle":"2022-02-12T14:37:12.753916Z","shell.execute_reply.started":"2022-02-12T14:37:12.749545Z","shell.execute_reply":"2022-02-12T14:37:12.752869Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.listdir(train_folder)\ntrain_normal = train_folder+'NORMAL/'\ntrain_pneumonia = train_folder+'PNEUMONIA/'","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:37:14.339152Z","iopub.execute_input":"2022-02-12T14:37:14.339612Z","iopub.status.idle":"2022-02-12T14:37:14.348530Z","shell.execute_reply.started":"2022-02-12T14:37:14.339576Z","shell.execute_reply":"2022-02-12T14:37:14.347761Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"os.listdir(val_folder)\nval_normal = val_folder+'NORMAL/'\nval_pneumonia = val_folder+'PNEUMONIA/'","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:37:16.083187Z","iopub.execute_input":"2022-02-12T14:37:16.083725Z","iopub.status.idle":"2022-02-12T14:37:16.092276Z","shell.execute_reply.started":"2022-02-12T14:37:16.083688Z","shell.execute_reply":"2022-02-12T14:37:16.091518Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"os.listdir(test_folder)\ntest_normal = test_folder+'NORMAL/'\ntest_pneumonia = test_folder+'PNEUMONIA/'","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:37:18.376034Z","iopub.execute_input":"2022-02-12T14:37:18.376784Z","iopub.status.idle":"2022-02-12T14:37:18.382789Z","shell.execute_reply.started":"2022-02-12T14:37:18.376746Z","shell.execute_reply":"2022-02-12T14:37:18.382018Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"labels = [\"NORMAL\", \"PNEUMONIA\"] # each folder has two sub folder name \"PNEUMONIA\", \"NORMAL\"\nIMG_SIZE = 50 # resize image\n\ndef get_data_train(data_dir):\n    data = []\n    for label in labels:\n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([new_array, class_num])\n                img_arr = np.asarray(img_array)\n            except Exception as e:\n                print(e)\n    return np.array(data)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:37:22.936819Z","iopub.execute_input":"2022-02-12T14:37:22.937304Z","iopub.status.idle":"2022-02-12T14:37:22.944372Z","shell.execute_reply.started":"2022-02-12T14:37:22.937267Z","shell.execute_reply":"2022-02-12T14:37:22.943281Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = get_data_train(train_folder)\ntest = get_data_train(test_folder)\nval = get_data_train(val_folder)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:53:04.796891Z","iopub.execute_input":"2022-02-12T14:53:04.797361Z","iopub.status.idle":"2022-02-12T14:54:25.610675Z","shell.execute_reply.started":"2022-02-12T14:53:04.797325Z","shell.execute_reply":"2022-02-12T14:54:25.609927Z"},"_kg_hide-output":true,"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"list = []\nfor i in train:\n    if(i[1] == 0):\n        list.append(\"Normal\")\n    else:\n        list.append(\"Pneumonia\")\n        \nsns.countplot(list)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:25:39.737467Z","iopub.execute_input":"2022-02-12T14:25:39.737664Z","iopub.status.idle":"2022-02-12T14:25:39.957805Z","shell.execute_reply.started":"2022-02-12T14:25:39.737639Z","shell.execute_reply":"2022-02-12T14:25:39.957080Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Normal pic \nprint(len(os.listdir(train_normal)))\n#random_normal= np.random.randint(0,len(os.listdir(train_normal)))\nnormal_picture = os.listdir(train_normal)[1]\nprint('normal picture title: ',normal_picture)\n\npath_image_normal = train_normal+normal_picture\n\n#Pneumonia\n#random_pneumonia = np.random.randint(0,len(os.listdir(train_pneumonia)))\npneumonia_picture =  os.listdir(train_pneumonia)[7]\npath_image_pneumonia = train_pneumonia+pneumonia_picture\nprint('pneumonia picture title:', pneumonia_picture)\n\n# Load the images\nnormal_load = Image.open(path_image_normal)\npneumonia_load = Image.open(path_image_pneumonia)\n\n#Let's plt these images\nf = plt.figure(figsize= (15,10))\na1 = f.add_subplot(1,2,1)\nimg_plot = plt.imshow(normal_load,cmap='gray', vmin=0, vmax=255)\na1.set_title('Normal')\n\na2 = f.add_subplot(1, 2, 2)\nplt.arrow(450, 500, 200, 300, head_width=30, head_length=30, fc='k', ec='white')\nplt.imshow(pneumonia_load,cmap='gray', vmin=0, vmax=255)\na2.set_title('Pneumonia')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:37:34.056013Z","iopub.execute_input":"2022-02-12T14:37:34.056841Z","iopub.status.idle":"2022-02-12T14:37:36.622249Z","shell.execute_reply.started":"2022-02-12T14:37:34.056792Z","shell.execute_reply":"2022-02-12T14:37:36.621616Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Building CNN Model**","metadata":{}},{"cell_type":"code","source":"num_of_test_samples = 500\nBATCH_SIZE = 32\nheight = 180\nwidth = 180\nEPOCHS = 25","metadata":{"execution":{"iopub.status.busy":"2022-02-12T14:40:30.874565Z","iopub.execute_input":"2022-02-12T14:40:30.874813Z","iopub.status.idle":"2022-02-12T14:40:30.879388Z","shell.execute_reply.started":"2022-02-12T14:40:30.874784Z","shell.execute_reply":"2022-02-12T14:40:30.878396Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model_CNN_Matt = tf.keras.Sequential([\n        tf.keras.Input(shape=(64,64,3)),\n        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding='same'),\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.MaxPool2D(),\n        \n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        tf.keras.layers.Dropout(0.2),\n        \n        #tf.keras.layers.Dense(512, activation='relu'),\n        #tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        #tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    return model_CNN_Matt","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:07:35.463921Z","iopub.execute_input":"2022-02-12T17:07:35.464544Z","iopub.status.idle":"2022-02-12T17:07:35.473833Z","shell.execute_reply.started":"2022-02-12T17:07:35.464504Z","shell.execute_reply":"2022-02-12T17:07:35.472860Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"model_CNN_Matt =  build_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:07:44.723546Z","iopub.execute_input":"2022-02-12T17:07:44.723842Z","iopub.status.idle":"2022-02-12T17:07:44.804603Z","shell.execute_reply.started":"2022-02-12T17:07:44.723810Z","shell.execute_reply":"2022-02-12T17:07:44.803882Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"model_CNN_Matt.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:07:46.289415Z","iopub.execute_input":"2022-02-12T17:07:46.289680Z","iopub.status.idle":"2022-02-12T17:07:46.302396Z","shell.execute_reply.started":"2022-02-12T17:07:46.289652Z","shell.execute_reply":"2022-02-12T17:07:46.301607Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"# Fitting the CNN to the images\n# The function ImageDataGenerator augments your image by iterating through image as your CNN is getting ready to process that image\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)  #Image normalization.\n\ntraining_set = train_datagen.flow_from_directory(train_folder,\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\nvalidation_generator = test_datagen.flow_from_directory(val_folder,\n                                                        target_size=(64, 64),\n                                                        batch_size=32,\n                                                        class_mode='binary')\n\ntest_set = test_datagen.flow_from_directory(test_folder,\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:07:51.488624Z","iopub.execute_input":"2022-02-12T17:07:51.488879Z","iopub.status.idle":"2022-02-12T17:07:52.546633Z","shell.execute_reply.started":"2022-02-12T17:07:51.488851Z","shell.execute_reply":"2022-02-12T17:07:52.545186Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"model_CNN_Matt = build_model()\nmetrics1 = ['accuracy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]\nmodel_CNN_Matt.compile(optimizer='adam',loss='binary_crossentropy',metrics=metrics1)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:08:14.939551Z","iopub.execute_input":"2022-02-12T17:08:14.940389Z","iopub.status.idle":"2022-02-12T17:08:15.027790Z","shell.execute_reply.started":"2022-02-12T17:08:14.940350Z","shell.execute_reply":"2022-02-12T17:08:15.027044Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(patience=5)\nchkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:08:17.143388Z","iopub.execute_input":"2022-02-12T17:08:17.143968Z","iopub.status.idle":"2022-02-12T17:08:17.148145Z","shell.execute_reply.started":"2022-02-12T17:08:17.143931Z","shell.execute_reply":"2022-02-12T17:08:17.147259Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"#Fit the model\nhistory = model_CNN_Matt.fit_generator(training_set,\n                         epochs = EPOCHS,\n                         validation_data = validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:08:19.263518Z","iopub.execute_input":"2022-02-12T17:08:19.264266Z","iopub.status.idle":"2022-02-12T17:31:06.062224Z","shell.execute_reply.started":"2022-02-12T17:08:19.264228Z","shell.execute_reply":"2022-02-12T17:31:06.061517Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"#evaluation on test set\naccuracy = model_CNN_Matt.evaluate(test_set, steps=300)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:32:38.979398Z","iopub.execute_input":"2022-02-12T17:32:38.979675Z","iopub.status.idle":"2022-02-12T17:32:44.963273Z","shell.execute_reply.started":"2022-02-12T17:32:38.979645Z","shell.execute_reply":"2022-02-12T17:32:44.962374Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T17:32:50.077456Z","iopub.execute_input":"2022-02-12T17:32:50.077935Z","iopub.status.idle":"2022-02-12T17:32:50.456631Z","shell.execute_reply.started":"2022-02-12T17:32:50.077885Z","shell.execute_reply":"2022-02-12T17:32:50.455844Z"},"trusted":true},"execution_count":215,"outputs":[]}]}